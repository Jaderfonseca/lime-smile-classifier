{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaderfonseca/lime-smile-classifier/blob/main/neural_network_with_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Synthetic \"smiley vs not_smile\" dataset (clean mouth logic) ===\n",
        "# Creates data/raw/{smile,not_smile}/*.png and data/raw/labels.csv\n",
        "\n",
        "import os, csv, random, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "\n",
        "# ---- Config (tweak freely) ----\n",
        "RANDOM_SEED    = 123\n",
        "IMG_SIZE       = 48          # larger than 32 to reduce blockiness\n",
        "N_PER_CLASS    = 500\n",
        "OUT_DIR        = Path(\"data/raw\")\n",
        "CLASSES        = [\"smile\", \"not_smile\"]\n",
        "\n",
        "STROKE         = 2           # line width for face/eyes/mouth\n",
        "ADD_NOISE_P    = 0.12        # prob. of adding blur+noise (lower for cleaner icons)\n",
        "NOISE_SIGMAS   = [0, 2, 3]   # std-dev options for Gaussian noise\n",
        "BLUR_RADIUS    = 0.35\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "(OUT_DIR / \"smile\").mkdir(parents=True, exist_ok=True)\n",
        "(OUT_DIR / \"not_smile\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _clip(lo, hi, x):\n",
        "    return max(lo, min(hi, x))\n",
        "\n",
        "def add_noise(img, sigma):\n",
        "    if sigma <= 0:\n",
        "        return img\n",
        "    arr   = np.array(img, dtype=np.int16)\n",
        "    noise = np.random.normal(0, sigma, arr.shape)\n",
        "    arr   = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(arr, mode=\"L\")\n",
        "\n",
        "def draw_mouth_curve(drw, x0, y0, x2, y2, cy, width, fg=0):\n",
        "    \"\"\"\n",
        "    Quadratic Bezier from (x0,y0) to (x2,y2) with control ( (x0+x2)/2 , cy ).\n",
        "    width = stroke width.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    xs, ys = [], []\n",
        "    cx = (x0 + x2) / 2.0\n",
        "    for t in np.linspace(0, 1, 50):\n",
        "        # Quadratic Bezier: B(t) = (1-t)^2 P0 + 2(1-t)t C + t^2 P2\n",
        "        bx = (1-t)**2 * x0 + 2*(1-t)*t * cx + t**2 * x2\n",
        "        by = (1-t)**2 * y0 + 2*(1-t)*t * cy + t**2 * y2\n",
        "        xs.append(bx); ys.append(by)\n",
        "    pts = list(map(tuple, np.stack([xs, ys], axis=1).astype(int)))\n",
        "    drw.line(pts, fill=fg, width=width)\n",
        "\n",
        "def draw_face(label=\"smile\"):\n",
        "    \"\"\"Return a 48x48 grayscale face with a clear smile or not_smile.\"\"\"\n",
        "    W = H = IMG_SIZE\n",
        "    bg, fg = 255, 0\n",
        "\n",
        "    # Canvas\n",
        "    img = Image.new(\"L\", (W, H), color=bg)\n",
        "    drw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Face (circle)\n",
        "    r  = random.randint(int(W*0.35), int(W*0.44))\n",
        "    cx = random.randint(int(W*0.48), int(W*0.52))\n",
        "    cy = random.randint(int(H*0.48), int(H*0.52))\n",
        "    bbox = [cx-r, cy-r, cx+r, cy+r]\n",
        "    drw.ellipse(bbox, outline=fg, width=STROKE)\n",
        "\n",
        "    # Eyes\n",
        "    eye_r  = random.randint(3, 4)\n",
        "    eye_dx = random.randint(6, 8)\n",
        "    eye_y  = cy - random.randint(int(H*0.10), int(H*0.14))\n",
        "\n",
        "    left_eye  = (cx - eye_dx - eye_r, eye_y - eye_r, cx - eye_dx + eye_r, eye_y + eye_r)\n",
        "    right_eye = (cx + eye_dx - eye_r, eye_y - eye_r, cx + eye_dx + eye_r, eye_y + eye_r)\n",
        "    drw.ellipse(left_eye,  fill=fg)\n",
        "    drw.ellipse(right_eye, fill=fg)\n",
        "\n",
        "    # Mouth baseline\n",
        "    mouth_w = random.randint(int(W*0.50), int(W*0.66))\n",
        "    mouth_y = random.randint(int(H*0.62), int(H*0.68))\n",
        "    x0 = cx - mouth_w//2\n",
        "    x2 = cx + mouth_w//2\n",
        "    y0 = y2 = mouth_y\n",
        "\n",
        "    # Curvature: positive -> control BELOW baseline (looks like a smile in image coords),\n",
        "    # negative -> control ABOVE baseline (frown). 0 -> flat.\n",
        "    base_curve = random.randint(6, 9)  # curvature magnitude in pixels (increase for more obvious)\n",
        "    if label == \"smile\":\n",
        "        cy_ctrl = mouth_y + base_curve + random.randint(0, 2)  # below baseline => U shape\n",
        "        draw_mouth_curve(drw, x0, y0, x2, y2, cy_ctrl, width=STROKE, fg=fg)\n",
        "    else:\n",
        "        mode = random.choice([\"frown\", \"flat\"])\n",
        "        if mode == \"flat\":\n",
        "            drw.line([(x0, mouth_y), (x2, mouth_y)], fill=fg, width=STROKE)\n",
        "        else:\n",
        "            cy_ctrl = mouth_y - base_curve - random.randint(0, 2)  # above baseline => ∩\n",
        "            draw_mouth_curve(drw, x0, y0, x2, y2, cy_ctrl, width=STROKE, fg=fg)\n",
        "\n",
        "    # Mild blur + optional noise (kept small so shapes stay recognizable)\n",
        "    if random.random() < ADD_NOISE_P:\n",
        "        img = img.filter(ImageFilter.GaussianBlur(radius=BLUR_RADIUS))\n",
        "        sigma = random.choice(NOISE_SIGMAS)\n",
        "        img = add_noise(img, sigma=sigma)\n",
        "\n",
        "    return img\n",
        "\n",
        "# ---- Generate and save ----\n",
        "rows = []\n",
        "for label in CLASSES:\n",
        "    for i in range(N_PER_CLASS):\n",
        "        img   = draw_face(label=label)\n",
        "        fname = f\"{label}_{i:04d}.png\"\n",
        "        fpath = OUT_DIR / label / fname\n",
        "        img.save(fpath)\n",
        "        rows.append({\"filepath\": str(fpath.as_posix()), \"label\": label})\n",
        "\n",
        "labels_csv = OUT_DIR / \"labels.csv\"\n",
        "with open(labels_csv, \"w\", newline=\"\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\"filepath\",\"label\"])\n",
        "    w.writeheader(); w.writerows(rows)\n",
        "\n",
        "print(f\"OK! Generated: {len(rows)} images\")\n",
        "print(f\" - {sum(r['label']=='smile' for r in rows)} smiles\")\n",
        "print(f\" - {sum(r['label']=='not_smile' for r in rows)} not_smile\")\n",
        "print(f\"CSV: {labels_csv}\")\n"
      ],
      "metadata": {
        "id": "27Fee8dgMgby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "df = pd.read_csv(\"data/raw/labels.csv\")\n",
        "sample = df.sample(25, random_state=42).reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "for i,(fp,lab) in enumerate(zip(sample[\"filepath\"], sample[\"label\"])):\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    ax.imshow(Image.open(fp), cmap=\"gray\")\n",
        "    ax.set_title(lab, fontsize=8)\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "emnfXvCkNBUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocess: images -> flat numeric vectors ---\n",
        "\n",
        "import json, csv, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RAW_DIR       = Path(\"data/raw\")\n",
        "PROC_DIR      = Path(\"data/processed\")\n",
        "LABELS_CSV    = RAW_DIR / \"labels.csv\"\n",
        "IMG_SIZE      = 48          # must match generation (or detect from first img)\n",
        "BINARIZE      = False       # set True to force 0/1 pixels\n",
        "THRESHOLD     = 128         # used if BINARIZE=True\n",
        "NORMALIZE     = True        # divide by 255 to [0,1]\n",
        "RANDOM_SEED   = 42\n",
        "\n",
        "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) load table\n",
        "rows = []\n",
        "with open(LABELS_CSV, \"r\") as f:\n",
        "    for r in csv.DictReader(f):\n",
        "        rows.append(r)\n",
        "\n",
        "print(f\"Loaded {len(rows)} filepaths from {LABELS_CSV}\")\n",
        "\n",
        "# 2) encode labels\n",
        "label_to_id = {\"smile\": 1, \"not_smile\": 0}\n",
        "id_to_label = {v:k for k,v in label_to_id.items()}\n",
        "\n",
        "# 3) loader + featurizer\n",
        "def load_as_vector(path):\n",
        "    img = Image.open(path).convert(\"L\")\n",
        "    if img.size != (IMG_SIZE, IMG_SIZE):\n",
        "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.NEAREST)\n",
        "\n",
        "    arr = np.array(img, dtype=np.uint8)\n",
        "\n",
        "    if BINARIZE:\n",
        "        arr = (arr >= THRESHOLD).astype(np.uint8) * 255\n",
        "\n",
        "    if NORMALIZE:\n",
        "        arr = arr.astype(np.float32) / 255.0\n",
        "    else:\n",
        "        arr = arr.astype(np.float32)\n",
        "\n",
        "    return arr.flatten()  # shape: (IMG_SIZE*IMG_SIZE,)\n"
      ],
      "metadata": {
        "id": "RGOVtFHPU-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build feature matrix\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for r in rows:\n",
        "    fp = r[\"filepath\"]\n",
        "    y_list.append(label_to_id[r[\"label\"]])\n",
        "    X_list.append(load_as_vector(fp))\n",
        "\n",
        "X = np.vstack(X_list)               # (N, IMG_SIZE*IMG_SIZE)\n",
        "y = np.array(y_list, dtype=np.int64)\n",
        "\n",
        "print(\"Feature matrix:\", X.shape, \"labels:\", y.shape)\n",
        "print(\"Class balance: smiles=\", (y==1).sum(), \" | not_smile=\", (y==0).sum())\n",
        "\n",
        "# stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# save arrays\n",
        "np.save(PROC_DIR / \"X_train.npy\", X_train)\n",
        "np.save(PROC_DIR / \"X_test.npy\",  X_test)\n",
        "np.save(PROC_DIR / \"y_train.npy\", y_train)\n",
        "np.save(PROC_DIR / \"y_test.npy\",  y_test)\n",
        "\n",
        "# save a tiny metadata companion for reproducibility\n",
        "meta = {\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"binarize\": BINARIZE,\n",
        "    \"threshold\": THRESHOLD,\n",
        "    \"normalize\": NORMALIZE,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"n_total\": int(X.shape[0]),\n",
        "    \"n_train\": int(X_train.shape[0]),\n",
        "    \"n_test\": int(X_test.shape[0]),\n",
        "    \"n_features\": int(X.shape[1]),\n",
        "    \"label_to_id\": label_to_id,\n",
        "}\n",
        "with open(PROC_DIR / \"preprocess_meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(\"Saved to:\", PROC_DIR)\n",
        "for p in [\"X_train.npy\",\"X_test.npy\",\"y_train.npy\",\"y_test.npy\",\"preprocess_meta.json\"]:\n",
        "    print(\" -\", PROC_DIR / p)\n"
      ],
      "metadata": {
        "id": "c0bmA7NFVA_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick checks\n",
        "Xt = np.load(PROC_DIR / \"X_train.npy\")\n",
        "yt = np.load(PROC_DIR / \"y_train.npy\")\n",
        "\n",
        "print(\"Shapes -> X_train:\", Xt.shape, \"| y_train:\", yt.shape)\n",
        "print(\"Means/std (first 5 cols):\", Xt[:, :5].mean(axis=0), Xt[:, :5].std(axis=0))\n",
        "print(\"Train balance:\", (yt==1).sum(), \"(smile) |\", (yt==0).sum(), \"(not_smile)\")\n"
      ],
      "metadata": {
        "id": "R8A6uAFJVTSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tiny MLP for smile vs not_smile (Keras/TF) ---\n",
        "\n",
        "import os, json, random, numpy as np\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "PROC_DIR = Path(\"data/processed\")\n",
        "MODEL_DIR = Path(\"models\"); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FIG_DIR = Path(\"figures\"); FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load processed data\n",
        "X_train = np.load(PROC_DIR / \"X_train.npy\")   # shape: (N, D)\n",
        "X_test  = np.load(PROC_DIR / \"X_test.npy\")\n",
        "y_train = np.load(PROC_DIR / \"y_train.npy\")   # shape: (N,)\n",
        "y_test  = np.load(PROC_DIR / \"y_test.npy\")\n",
        "\n",
        "print(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scale inputs to [0,1] if not already\n",
        "if X_train.max() > 1.0:\n",
        "    X_train = X_train / 255.0\n",
        "    X_test  = X_test  / 255.0\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Build a small MLP (2 hidden layers)\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "def make_model(input_dim: int) -> tf.keras.Model:\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.15)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.10)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = make_model(input_dim)\n",
        "model.summary()\n",
        "\n",
        "# Callbacks: early stopping + best model checkpoint\n",
        "ckpt_path = str(MODEL_DIR / \"mlp_smile_best.keras\")\n",
        "cbs = [\n",
        "    callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "    callbacks.ModelCheckpoint(ckpt_path, monitor=\"val_accuracy\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=60,\n",
        "    batch_size=64,\n",
        "    callbacks=cbs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save final model and training history\n",
        "model.save(MODEL_DIR / \"mlp_smile_final.keras\")\n",
        "with open(MODEL_DIR / \"mlp_smile_history.json\", \"w\") as f:\n",
        "    json.dump({k: [float(v) for v in vals] for k, vals in history.history.items()}, f)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}  |  Test loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predictions & reports\n",
        "y_prob = model.predict(X_test, verbose=0).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification report:\\n\",\n",
        "      classification_report(y_test, y_pred, target_names=[\"not_smile\",\"smile\"]))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot: training curves\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"MLP accuracy\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_accuracy.png\", dpi=160)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP loss\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_loss.png\", dpi=160)\n",
        "plt.show()\n",
        "\n",
        "# Plot: confusion matrix\n",
        "plt.figure(figsize=(4.8,4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick = np.arange(2)\n",
        "plt.xticks(tick, [\"not_smile\",\"smile\"])\n",
        "plt.yticks(tick, [\"not_smile\",\"smile\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=12)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_confusion_matrix.png\", dpi=160)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PNwaj41gY4Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"models/mlp_smile_classifier.keras\")\n"
      ],
      "metadata": {
        "id": "aDPmWozzcgAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "# salvar modelo e histórico\n",
        "model.save(\"models/mlp_smile_classifier.keras\")\n",
        "np.save(\"results/history.npy\", history.history)\n"
      ],
      "metadata": {
        "id": "J4pEMH7idFG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1) Compute metrics ---\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np, os\n",
        "\n",
        "# predictions\n",
        "proba = model.predict(X_test, verbose=0).ravel()\n",
        "y_pred = (proba >= 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test accuracy: {acc:.3f}\")\n",
        "\n",
        "report = classification_report(y_test, y_pred, target_names=[\"not_smile\",\"smile\"])\n",
        "print(report)\n",
        "\n",
        "# save report to file\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "with open(\"results/classification_report.txt\", \"w\") as f:\n",
        "    f.write(f\"Test accuracy: {acc:.3f}\\n\\n\")\n",
        "    f.write(report)\n",
        "\n",
        "# --- 2) Confusion matrix ---\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "im = ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
        "ax.set_xticklabels([\"not_smile\",\"smile\"]); ax.set_yticklabels([\"not_smile\",\"smile\"])\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=12)\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{FIG_DIR}/confusion_matrix.png\", dpi=160, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# --- 3) Accuracy per epoch (if history exists) ---\n",
        "if os.path.exists(\"results/history.npy\"):\n",
        "    hist = np.load(\"results/history.npy\", allow_pickle=True).item()\n",
        "    train_acc = hist.get(\"accuracy\", [])\n",
        "    val_acc   = hist.get(\"val_accuracy\", [])\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    if train_acc: plt.plot(train_acc, label=\"train acc\")\n",
        "    if val_acc:   plt.plot(val_acc,   label=\"val acc\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"MLP accuracy\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{FIG_DIR}/accuracy.png\", dpi=160, bbox_inches=\"tight\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WLOSFX9x78vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal evaluation saver: writes files without displaying plots\n",
        "import os, numpy as np, matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "# 1) Metrics → results/classification_report.txt\n",
        "proba  = model.predict(X_test, verbose=0).ravel()\n",
        "y_pred = (proba >= 0.5).astype(int)\n",
        "acc    = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=[\"not_smile\",\"smile\"])\n",
        "\n",
        "with open(\"results/classification_report.txt\", \"w\") as f:\n",
        "    f.write(f\"Test accuracy: {acc:.3f}\\n\\n\")\n",
        "    f.write(report)\n",
        "\n",
        "# 2) Confusion matrix → figures/confusion_matrix.png\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "im = ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.figure.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
        "ax.set_xticklabels([\"not_smile\",\"smile\"]); ax.set_yticklabels([\"not_smile\",\"smile\"])\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=12)\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/confusion_matrix.png\", dpi=160, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "# 3) Accuracy per epoch (if history exists) → figures/accuracy.png\n",
        "if os.path.exists(\"results/history.npy\"):\n",
        "    hist = np.load(\"results/history.npy\", allow_pickle=True).item()\n",
        "    train_acc = hist.get(\"accuracy\", [])\n",
        "    val_acc   = hist.get(\"val_accuracy\", [])\n",
        "\n",
        "    fig2, ax2 = plt.subplots(figsize=(6,4))\n",
        "    if train_acc: ax2.plot(train_acc, label=\"train acc\")\n",
        "    if val_acc:   ax2.plot(val_acc,   label=\"val acc\")\n",
        "    ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Accuracy\"); ax2.set_title(\"MLP accuracy\")\n",
        "    ax2.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/accuracy.png\", dpi=160, bbox_inches=\"tight\")\n",
        "    plt.close(fig2)\n"
      ],
      "metadata": {
        "id": "0aa0feI-_dm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- First LIME explanation (48x48 grayscale) ---\n",
        "\n",
        "# 1) install & imports\n",
        "!pip -q install lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from keras.models import load_model\n",
        "import numpy as np, matplotlib.pyplot as plt, os\n",
        "\n",
        "# 2) config & load artifacts\n",
        "IMG_SIZE = 48                        # your images are 48x48\n",
        "MODEL_PATH = \"models/mlp_smile_final.keras\"\n",
        "X_TEST = \"data/processed/X_test.npy\"\n",
        "Y_TEST = \"data/processed/y_test.npy\"\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "X_test = np.load(X_TEST)            # shape: (N, 48*48)\n",
        "y_test = np.load(Y_TEST)            # 0 = not_smile, 1 = smile\n",
        "\n",
        "# LIME sends RGB (48x48x3). Convert to grayscale and flatten. ---\n",
        "import numpy as np\n",
        "\n",
        "def predict_fn(images):\n",
        "  arr = np.array(images)\n",
        "\n",
        "  # if LIME gives RGB, convert to grayscale by channel mean\n",
        "  if arr.ndim == 4 and arr.shape[-1] == 3: #(B, 48, 48, 3)\n",
        "      arr = arr.mean(axis=-1)             # ->(B, 48, 48)\n",
        "\n",
        "  # Ensure shape is (B, 48, 48)\n",
        "  if arr.ndim == 2:                       # single image (48, 48)\n",
        "      arr = arr[None, ...]\n",
        "\n",
        "  # Scale to [0,1] if values likely in 0..255\n",
        "  if arr.max() > 1.5:\n",
        "      arr = arr / 255.0\n",
        "\n",
        "  flat = arr.reshape(len(arr), -1)                  # (B, 2304)\n",
        "  p_smile = model.predict(flat, verbose=0).reshape(-1, 1)  # sigmoid output\n",
        "  return np.hstack([1 - p_smile, p_smile])\n",
        "\n",
        "# 4) pick one positive and one negative example to test\n",
        "pos_idx = int(np.where(y_test == 1)[0][0])    # first \"smile\"\n",
        "neg_idx = int(np.where(y_test == 0)[0][0])    # first \"not_smile\"\n",
        "\n",
        "def run_lime(idx: int, tag: str):\n",
        "    \"\"\"Generate one LIME explanation and save to figures/lime_{tag}.png\"\"\"\n",
        "    sample = X_test[idx].reshape(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "    explanation = explainer.explain_instance(\n",
        "        image=sample,                 # 2D grayscale\n",
        "        classifier_fn=predict_fn,     # returns (B, 2) probs\n",
        "        labels=[0, 1],                # 0=not_smile, 1=smile\n",
        "        num_samples=800,              # increase for more stability (slower)\n",
        "    )\n",
        "\n",
        "    # visualize contributions for the true label\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=int(y_test[idx]),\n",
        "        positive_only=False,          # show both positive/negative regions\n",
        "        hide_rest=False,\n",
        "        num_features=6,               # number of superpixels to show\n",
        "        min_weight=0.0,\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(mark_boundaries(temp, mask), cmap=\"gray\")\n",
        "    plt.title(f\"LIME — idx {idx} | true: {'smile' if y_test[idx]==1 else 'not_smile'}\")\n",
        "    plt.axis(\"off\")\n",
        "    out = os.path.join(FIG_DIR, f\"lime_{tag}.png\")\n",
        "    plt.savefig(out, dpi=180, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {out}\")\n",
        "\n",
        "# 5) run once for each class\n",
        "run_lime(pos_idx, \"sample_smile\")\n",
        "run_lime(neg_idx, \"sample_not_smile\")\n"
      ],
      "metadata": {
        "id": "Ae-NUUgvC4XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Make sure the folders exist\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "# --- Save model ---\n",
        "model.save(\"models/mlp_smile_final.keras\")\n",
        "\n",
        "# --- Save training history (as .npy) ---\n",
        "np.save(\"results/history.npy\", history.history)\n",
        "\n",
        "# --- Save training history (as .json) ---\n",
        "with open(\"results/mlp_history.json\", \"w\") as f:\n",
        "    json.dump(history.history, f)\n"
      ],
      "metadata": {
        "id": "p6y4RNMdNiDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}