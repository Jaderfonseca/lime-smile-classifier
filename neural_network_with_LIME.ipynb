{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaderfonseca/lime-smile-classifier/blob/main/neural_network_with_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpreting Toy Neural Networks with LIME\n",
        "**Mini‑project** · Portfolio-ready version\n",
        "\n",
        "This notebook demonstrates a compact, reproducible pipeline for training a small Multi-Layer Perceptron (MLP) to classify smiles vs. not smile from grayscale face images. Beyond accuracy, it integrates interpretability via LIME (Local Interpretable Model-Agnostic Explanations), highlighting regions of the face that drive the model’s predictions. It is intentionally compact and reproducible for reviewers."
      ],
      "metadata": {
        "id": "9kv5YW1MK-ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to run\n",
        "\n",
        "\n",
        "1. Open in Google Colab or a local Jupyter environment.\n",
        "\n",
        "2. Run the Setup cell to install dependencies.\n",
        "\n",
        "3. Execute cells in order: Data loading → Preprocessing → Model → Training → Metrics → Interpretability (LIME).\n",
        "\n",
        "4. Outputs (models, reports, figures) are saved into structured folders.\n",
        "\n"
      ],
      "metadata": {
        "id": "TaKNWlzQL8vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Folder structure**\n",
        "\n",
        "- `data/processed/` – preprocessed train/test arrays (X_train.npy, y_train.npy, …)\n",
        "\n",
        "- `models/` – saved Keras models (mlp_smile_best.keras, mlp_smile_final.keras)\n",
        "\n",
        "- `results/` – evaluation reports (classification_report.txt, JSON history)\n",
        "\n",
        "- `figures/` – accuracy/loss curves, confusion matrix, and LIME explanations"
      ],
      "metadata": {
        "id": "uPuBAZ4FMXfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Smile Classification — Minimal, Reproducible Pipeline**\n",
        "\n",
        "1. This notebook:\n",
        "\n",
        "2. Loads preprocessed data.\n",
        "\n",
        "3. Builds and trains a compact MLP with dropout regularization.\n",
        "\n",
        "4. Evaluates performance (accuracy, loss, confusion matrix, classification report).\n",
        "\n",
        "5. Saves trained models and metrics for reproducibility.\n",
        "\n",
        "6. Produces LIME explanations to visualize which facial regions drive predictions."
      ],
      "metadata": {
        "id": "ky93ABZUNvUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Synthetic \"smile vs not_smile\" dataset generator ===\n",
        "# Outputs:\n",
        "#   - PNG icons for each class in: data/raw/{smile,not_smile}/*.png\n",
        "#   - A label index file: data/raw/labels.csv\n",
        "\n",
        "import os, csv, random, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFilter\n",
        "\n",
        "# ---- Config (tweak freely) ----\n",
        "RANDOM_SEED    = 123\n",
        "IMG_SIZE       = 48          # larger than 32 to reduce blockiness\n",
        "N_PER_CLASS    = 500\n",
        "OUT_DIR        = Path(\"data/raw\")\n",
        "CLASSES        = [\"smile\", \"not_smile\"]\n",
        "\n",
        "STROKE         = 2           # line width for face/eyes/mouth\n",
        "ADD_NOISE_P    = 0.12        # prob. of adding blur+noise (lower for cleaner icons)\n",
        "NOISE_SIGMAS   = [0, 2, 3]   # std-dev options for Gaussian noise\n",
        "BLUR_RADIUS    = 0.35\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "(OUT_DIR / \"smile\").mkdir(parents=True, exist_ok=True)\n",
        "(OUT_DIR / \"not_smile\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _clip(lo, hi, x):\n",
        "    return max(lo, min(hi, x))\n",
        "\n",
        "def add_noise(img, sigma):\n",
        "    if sigma <= 0:\n",
        "        return img\n",
        "    arr   = np.array(img, dtype=np.int16)\n",
        "    noise = np.random.normal(0, sigma, arr.shape)\n",
        "    arr   = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
        "    return Image.fromarray(arr, mode=\"L\")\n",
        "\n",
        "def draw_mouth_curve(drw, x0, y0, x2, y2, cy, width, fg=0):\n",
        "    \"\"\"\n",
        "    Quadratic Bezier from (x0,y0) to (x2,y2) with control ( (x0+x2)/2 , cy ).\n",
        "    width = stroke width.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    xs, ys = [], []\n",
        "    cx = (x0 + x2) / 2.0\n",
        "    for t in np.linspace(0, 1, 50):\n",
        "        # Quadratic Bezier: B(t) = (1-t)^2 P0 + 2(1-t)t C + t^2 P2\n",
        "        bx = (1-t)**2 * x0 + 2*(1-t)*t * cx + t**2 * x2\n",
        "        by = (1-t)**2 * y0 + 2*(1-t)*t * cy + t**2 * y2\n",
        "        xs.append(bx); ys.append(by)\n",
        "    pts = list(map(tuple, np.stack([xs, ys], axis=1).astype(int)))\n",
        "    drw.line(pts, fill=fg, width=width)\n",
        "\n",
        "def draw_face(label=\"smile\"):\n",
        "    \"\"\"Return a 48x48 grayscale face with a clear smile or not_smile.\"\"\"\n",
        "    W = H = IMG_SIZE\n",
        "    bg, fg = 255, 0\n",
        "\n",
        "    # Canvas\n",
        "    img = Image.new(\"L\", (W, H), color=bg)\n",
        "    drw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Face (circle)\n",
        "    r  = random.randint(int(W*0.35), int(W*0.44))\n",
        "    cx = random.randint(int(W*0.48), int(W*0.52))\n",
        "    cy = random.randint(int(H*0.48), int(H*0.52))\n",
        "    bbox = [cx-r, cy-r, cx+r, cy+r]\n",
        "    drw.ellipse(bbox, outline=fg, width=STROKE)\n",
        "\n",
        "    # Eyes\n",
        "    eye_r  = random.randint(3, 4)\n",
        "    eye_dx = random.randint(6, 8)\n",
        "    eye_y  = cy - random.randint(int(H*0.10), int(H*0.14))\n",
        "\n",
        "    left_eye  = (cx - eye_dx - eye_r, eye_y - eye_r, cx - eye_dx + eye_r, eye_y + eye_r)\n",
        "    right_eye = (cx + eye_dx - eye_r, eye_y - eye_r, cx + eye_dx + eye_r, eye_y + eye_r)\n",
        "    drw.ellipse(left_eye,  fill=fg)\n",
        "    drw.ellipse(right_eye, fill=fg)\n",
        "\n",
        "    # Mouth baseline\n",
        "    mouth_w = random.randint(int(W*0.50), int(W*0.66))\n",
        "    mouth_y = random.randint(int(H*0.62), int(H*0.68))\n",
        "    x0 = cx - mouth_w//2\n",
        "    x2 = cx + mouth_w//2\n",
        "    y0 = y2 = mouth_y\n",
        "\n",
        "    # Curvature: positive -> control BELOW baseline (looks like a smile in image coords),\n",
        "    # negative -> control ABOVE baseline (frown). 0 -> flat.\n",
        "    base_curve = random.randint(6, 9)  # curvature magnitude in pixels (increase for more obvious)\n",
        "    if label == \"smile\":\n",
        "        cy_ctrl = mouth_y + base_curve + random.randint(0, 2)  # below baseline => U shape\n",
        "        draw_mouth_curve(drw, x0, y0, x2, y2, cy_ctrl, width=STROKE, fg=fg)\n",
        "    else:\n",
        "        mode = random.choice([\"frown\", \"flat\"])\n",
        "        if mode == \"flat\":\n",
        "            drw.line([(x0, mouth_y), (x2, mouth_y)], fill=fg, width=STROKE)\n",
        "        else:\n",
        "            cy_ctrl = mouth_y - base_curve - random.randint(0, 2)  # above baseline => ∩\n",
        "            draw_mouth_curve(drw, x0, y0, x2, y2, cy_ctrl, width=STROKE, fg=fg)\n",
        "\n",
        "    # Mild blur + optional noise (kept small so shapes stay recognizable)\n",
        "    if random.random() < ADD_NOISE_P:\n",
        "        img = img.filter(ImageFilter.GaussianBlur(radius=BLUR_RADIUS))\n",
        "        sigma = random.choice(NOISE_SIGMAS)\n",
        "        img = add_noise(img, sigma=sigma)\n",
        "\n",
        "    return img\n",
        "\n",
        "# ---- Generate and save ----\n",
        "rows = []\n",
        "for label in CLASSES:\n",
        "    for i in range(N_PER_CLASS):\n",
        "        img   = draw_face(label=label)\n",
        "        fname = f\"{label}_{i:04d}.png\"\n",
        "        fpath = OUT_DIR / label / fname\n",
        "        img.save(fpath)\n",
        "        rows.append({\"filepath\": str(fpath.as_posix()), \"label\": label})\n",
        "\n",
        "labels_csv = OUT_DIR / \"labels.csv\"\n",
        "with open(labels_csv, \"w\", newline=\"\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\"filepath\",\"label\"])\n",
        "    w.writeheader(); w.writerows(rows)\n",
        "\n",
        "print(f\"OK! Generated: {len(rows)} images\")\n",
        "print(f\" - {sum(r['label']=='smile' for r in rows)} smiles\")\n",
        "print(f\" - {sum(r['label']=='not_smile' for r in rows)} not_smile\")\n",
        "print(f\"CSV: {labels_csv}\")\n"
      ],
      "metadata": {
        "id": "27Fee8dgMgby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "df = pd.read_csv(\"data/raw/labels.csv\")\n",
        "sample = df.sample(25, random_state=42).reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "for i,(fp,lab) in enumerate(zip(sample[\"filepath\"], sample[\"label\"])):\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    ax.imshow(Image.open(fp), cmap=\"gray\")\n",
        "    ax.set_title(lab, fontsize=8)\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "emnfXvCkNBUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocess: images -> flat numeric vectors ---\n",
        "\n",
        "import json, csv, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RAW_DIR       = Path(\"data/raw\")\n",
        "PROC_DIR      = Path(\"data/processed\")\n",
        "LABELS_CSV    = RAW_DIR / \"labels.csv\"\n",
        "IMG_SIZE      = 48          # must match generation (or detect from first img)\n",
        "BINARIZE      = False       # set True to force 0/1 pixels\n",
        "THRESHOLD     = 128         # used if BINARIZE=True\n",
        "NORMALIZE     = True        # divide by 255 to [0,1]\n",
        "RANDOM_SEED   = 42\n",
        "\n",
        "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) load table\n",
        "rows = []\n",
        "with open(LABELS_CSV, \"r\") as f:\n",
        "    for r in csv.DictReader(f):\n",
        "        rows.append(r)\n",
        "\n",
        "print(f\"Loaded {len(rows)} filepaths from {LABELS_CSV}\")\n",
        "\n",
        "# 2) encode labels\n",
        "label_to_id = {\"smile\": 1, \"not_smile\": 0}\n",
        "id_to_label = {v:k for k,v in label_to_id.items()}\n",
        "\n",
        "# 3) loader + featurizer\n",
        "def load_as_vector(path):\n",
        "    img = Image.open(path).convert(\"L\")\n",
        "    if img.size != (IMG_SIZE, IMG_SIZE):\n",
        "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.NEAREST)\n",
        "\n",
        "    arr = np.array(img, dtype=np.uint8)\n",
        "\n",
        "    if BINARIZE:\n",
        "        arr = (arr >= THRESHOLD).astype(np.uint8) * 255\n",
        "\n",
        "    if NORMALIZE:\n",
        "        arr = arr.astype(np.float32) / 255.0\n",
        "    else:\n",
        "        arr = arr.astype(np.float32)\n",
        "\n",
        "    return arr.flatten()  # shape: (IMG_SIZE*IMG_SIZE,)\n"
      ],
      "metadata": {
        "id": "RGOVtFHPU-Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build feature matrix\n",
        "X_list, y_list = [], []\n",
        "\n",
        "for r in rows:\n",
        "    fp = r[\"filepath\"]\n",
        "    y_list.append(label_to_id[r[\"label\"]])\n",
        "    X_list.append(load_as_vector(fp))\n",
        "\n",
        "X = np.vstack(X_list)               # (N, IMG_SIZE*IMG_SIZE)\n",
        "y = np.array(y_list, dtype=np.int64)\n",
        "\n",
        "print(\"Feature matrix:\", X.shape, \"labels:\", y.shape)\n",
        "print(\"Class balance: smiles=\", (y==1).sum(), \" | not_smile=\", (y==0).sum())\n",
        "\n",
        "# stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# save arrays\n",
        "np.save(PROC_DIR / \"X_train.npy\", X_train)\n",
        "np.save(PROC_DIR / \"X_test.npy\",  X_test)\n",
        "np.save(PROC_DIR / \"y_train.npy\", y_train)\n",
        "np.save(PROC_DIR / \"y_test.npy\",  y_test)\n",
        "\n",
        "# save a tiny metadata companion for reproducibility\n",
        "meta = {\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"binarize\": BINARIZE,\n",
        "    \"threshold\": THRESHOLD,\n",
        "    \"normalize\": NORMALIZE,\n",
        "    \"random_seed\": RANDOM_SEED,\n",
        "    \"n_total\": int(X.shape[0]),\n",
        "    \"n_train\": int(X_train.shape[0]),\n",
        "    \"n_test\": int(X_test.shape[0]),\n",
        "    \"n_features\": int(X.shape[1]),\n",
        "    \"label_to_id\": label_to_id,\n",
        "}\n",
        "with open(PROC_DIR / \"preprocess_meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(\"Saved to:\", PROC_DIR)\n",
        "for p in [\"X_train.npy\",\"X_test.npy\",\"y_train.npy\",\"y_test.npy\",\"preprocess_meta.json\"]:\n",
        "    print(\" -\", PROC_DIR / p)\n"
      ],
      "metadata": {
        "id": "c0bmA7NFVA_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Tiny MLP for smile vs not_smile (Keras/TF) ---\n",
        "\n",
        "import os, json, random, numpy as np\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "PROC_DIR = Path(\"data/processed\")\n",
        "MODEL_DIR = Path(\"models\"); MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FIG_DIR = Path(\"figures\"); FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load processed data\n",
        "X_train = np.load(PROC_DIR / \"X_train.npy\")   # shape: (N, D)\n",
        "X_test  = np.load(PROC_DIR / \"X_test.npy\")\n",
        "y_train = np.load(PROC_DIR / \"y_train.npy\")   # shape: (N,)\n",
        "y_test  = np.load(PROC_DIR / \"y_test.npy\")\n",
        "\n",
        "print(\"Shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# Scale inputs to [0,1] if not already\n",
        "if X_train.max() > 1.0:\n",
        "    X_train = X_train / 255.0\n",
        "    X_test  = X_test  / 255.0\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Build a small MLP (2 hidden layers)\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "def make_model(input_dim: int) -> tf.keras.Model:\n",
        "    inputs = layers.Input(shape=(input_dim,))\n",
        "    x = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.15)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.10)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = make_model(input_dim)\n",
        "model.summary()\n",
        "\n",
        "# Callbacks: early stopping + best model checkpoint\n",
        "ckpt_path = str(MODEL_DIR / \"mlp_smile_best.keras\")\n",
        "cbs = [\n",
        "    callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "    callbacks.ModelCheckpoint(ckpt_path, monitor=\"val_accuracy\", save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=60,\n",
        "    batch_size=64,\n",
        "    callbacks=cbs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save final model and training history\n",
        "model.save(MODEL_DIR / \"mlp_smile_final.keras\")\n",
        "with open(MODEL_DIR / \"mlp_smile_history.json\", \"w\") as f:\n",
        "    json.dump({k: [float(v) for v in vals] for k, vals in history.history.items()}, f)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}  |  Test loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predictions & reports\n",
        "y_prob = model.predict(X_test, verbose=0).ravel()\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\nClassification report:\\n\",\n",
        "      classification_report(y_test, y_pred, target_names=[\"not_smile\",\"smile\"]))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# --- Save classification report to .txt ---\n",
        "RESULTS_DIR = Path(\"results\")\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "acc = (y_pred == y_test).mean()\n",
        "with open(RESULTS_DIR / \"classification_report.txt\", \"w\") as f:\n",
        "    f.write(f\"Test accuracy: {acc:.3f}\\n\\n\")\n",
        "    f.write(classification_report(y_test, y_pred, target_names=[\"not_smile\",\"smile\"]))\n",
        "\n",
        "# Plot: training curves\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val acc\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"MLP accuracy\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_accuracy.png\", dpi=160)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP loss\")\n",
        "plt.legend(); plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_loss.png\", dpi=160)\n",
        "plt.show()\n",
        "\n",
        "# Plot: confusion matrix\n",
        "plt.figure(figsize=(4.8,4))\n",
        "plt.imshow(cm, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick = np.arange(2)\n",
        "plt.xticks(tick, [\"not_smile\",\"smile\"])\n",
        "plt.yticks(tick, [\"not_smile\",\"smile\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=12)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / \"mlp_confusion_matrix.png\", dpi=160)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QQOvFcoDqud2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- First LIME explanation (48x48 grayscale) ---\n",
        "\n",
        "# 1) install & imports\n",
        "!pip -q install lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from keras.models import load_model\n",
        "import numpy as np, matplotlib.pyplot as plt, os\n",
        "\n",
        "# 2) config & load artifacts\n",
        "IMG_SIZE = 48                        # your images are 48x48\n",
        "MODEL_PATH = \"models/mlp_smile_final.keras\"\n",
        "X_TEST = \"data/processed/X_test.npy\"\n",
        "Y_TEST = \"data/processed/y_test.npy\"\n",
        "FIG_DIR = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "model = load_model(MODEL_PATH)\n",
        "X_test = np.load(X_TEST)            # shape: (N, 48*48)\n",
        "y_test = np.load(Y_TEST)            # 0 = not_smile, 1 = smile\n",
        "\n",
        "# LIME sends RGB (48x48x3). Convert to grayscale and flatten. ---\n",
        "import numpy as np\n",
        "\n",
        "def predict_fn(images):\n",
        "  arr = np.array(images)\n",
        "\n",
        "  # if LIME gives RGB, convert to grayscale by channel mean\n",
        "  if arr.ndim == 4 and arr.shape[-1] == 3: #(B, 48, 48, 3)\n",
        "      arr = arr.mean(axis=-1)             # ->(B, 48, 48)\n",
        "\n",
        "  # Ensure shape is (B, 48, 48)\n",
        "  if arr.ndim == 2:                       # single image (48, 48)\n",
        "      arr = arr[None, ...]\n",
        "\n",
        "  # Scale to [0,1] if values likely in 0..255\n",
        "  if arr.max() > 1.5:\n",
        "      arr = arr / 255.0\n",
        "\n",
        "  flat = arr.reshape(len(arr), -1)                  # (B, 2304)\n",
        "  p_smile = model.predict(flat, verbose=0).reshape(-1, 1)  # sigmoid output\n",
        "  return np.hstack([1 - p_smile, p_smile])\n",
        "\n",
        "# 4) pick one positive and one negative example to test\n",
        "pos_idx = int(np.where(y_test == 1)[0][0])    # first \"smile\"\n",
        "neg_idx = int(np.where(y_test == 0)[0][0])    # first \"not_smile\"\n",
        "\n",
        "def run_lime(idx: int, tag: str):\n",
        "    \"\"\"Generate one LIME explanation and save to figures/lime_{tag}.png\"\"\"\n",
        "    sample = X_test[idx].reshape(IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "    explanation = explainer.explain_instance(\n",
        "        image=sample,                 # 2D grayscale\n",
        "        classifier_fn=predict_fn,     # returns (B, 2) probs\n",
        "        labels=[0, 1],                # 0=not_smile, 1=smile\n",
        "        num_samples=800,              # increase for more stability (slower)\n",
        "    )\n",
        "\n",
        "    # visualize contributions for the true label\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=int(y_test[idx]),\n",
        "        positive_only=False,          # show both positive/negative regions\n",
        "        hide_rest=False,\n",
        "        num_features=6,               # number of superpixels to show\n",
        "        min_weight=0.0,\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(mark_boundaries(temp, mask), cmap=\"gray\")\n",
        "    plt.title(f\"LIME — idx {idx} | true: {'smile' if y_test[idx]==1 else 'not_smile'}\")\n",
        "    plt.axis(\"off\")\n",
        "    out = os.path.join(FIG_DIR, f\"lime_{tag}.png\")\n",
        "    plt.savefig(out, dpi=180, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved: {out}\")\n",
        "\n",
        "# 5) run once for each class\n",
        "run_lime(pos_idx, \"sample_smile\")\n",
        "run_lime(neg_idx, \"sample_not_smile\")\n"
      ],
      "metadata": {
        "id": "Ae-NUUgvC4XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install lime\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import slic, mark_boundaries\n",
        "from keras.models import load_model\n",
        "import numpy as np, matplotlib.pyplot as plt, os\n",
        "\n",
        "# --- configuration ---\n",
        "IMG_SIZE     = 48\n",
        "MODEL_PATH   = \"models/mlp_smile_final.keras\"\n",
        "X_TEST_PATH  = \"data/processed/X_test.npy\"\n",
        "Y_TEST_PATH  = \"data/processed/y_test.npy\"\n",
        "FIG_DIR      = \"figures\"\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "N_TOTAL      = 10       # total explanations to generate\n",
        "NUM_SAMPLES  = 800      # higher = more stable, but slower\n",
        "NUM_FEATURES = 6        # number of superpixels highlighted\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# --- load model and data ---\n",
        "model  = load_model(MODEL_PATH)\n",
        "X_test = np.load(X_TEST_PATH, allow_pickle=True)\n",
        "y_test = np.load(Y_TEST_PATH, allow_pickle=True).astype(int)\n",
        "\n",
        "def to_2d(xrow):\n",
        "    return xrow.reshape(IMG_SIZE, IMG_SIZE) if xrow.ndim == 1 else xrow\n",
        "\n",
        "# Balanced sampling across classes\n",
        "rng = np.random.default_rng(RANDOM_STATE)\n",
        "idx_pos = rng.permutation(np.where(y_test == 1)[0]).tolist()\n",
        "idx_neg = rng.permutation(np.where(y_test == 0)[0]).tolist()\n",
        "half = N_TOTAL // 2\n",
        "picked = idx_pos[:half] + idx_neg[:(N_TOTAL - half)]\n",
        "rng.shuffle(picked)\n",
        "\n",
        "# Predictor for LIME\n",
        "def predict_fn(images):\n",
        "    arr = np.array(images)\n",
        "    if arr.ndim == 3:  # single image\n",
        "        arr = arr[None, ...]\n",
        "    arr = arr.astype(\"float32\")\n",
        "    if arr.max() > 1.5:\n",
        "        arr = arr / 255.0\n",
        "    if arr.shape[-1] == 3:  # RGB -> grayscale\n",
        "        arr = arr.mean(axis=-1)\n",
        "    flat = arr.reshape(len(arr), -1)\n",
        "    p_smile = model.predict(flat, verbose=0).reshape(-1, 1)  # sigmoid\n",
        "    return np.hstack([1 - p_smile, p_smile])                 # [not_smile, smile]\n",
        "\n",
        "# Init explainer with seed (do NOT pass random_state to explain_instance)\n",
        "explainer = lime_image.LimeImageExplainer(random_state=RANDOM_STATE)\n",
        "\n",
        "def explain_and_save(idx, out_path):\n",
        "    img2d = to_2d(X_test[idx])\n",
        "\n",
        "    # Robust SLIC (new/old scikit-image)\n",
        "    def seg_fn(x):\n",
        "        x = np.asarray(x)\n",
        "        if x.ndim == 2:\n",
        "            x = np.repeat(x[..., None], 3, axis=-1)\n",
        "        x = x.astype(\"float32\")\n",
        "        if x.max() > 1.5:\n",
        "            x = x / 255.0\n",
        "        try:\n",
        "            return slic(x, n_segments=50, compactness=10, start_label=0, channel_axis=-1)\n",
        "        except TypeError:\n",
        "            return slic(x, n_segments=50, compactness=10, start_label=0)\n",
        "\n",
        "    exp = explainer.explain_instance(\n",
        "        image=img2d,                  # 2D grayscale\n",
        "        classifier_fn=predict_fn,\n",
        "        labels=[0, 1],\n",
        "        num_samples=NUM_SAMPLES,\n",
        "        segmentation_fn=seg_fn\n",
        "    )\n",
        "\n",
        "    # Model prediction for title\n",
        "    rgb = np.repeat(img2d[..., None], 3, axis=-1)\n",
        "    probs = predict_fn(rgb[None, ...])[0]\n",
        "    pred = int(np.argmax(probs))\n",
        "    p_smile = float(probs[1])\n",
        "\n",
        "    # Visualize explanation for the TRUE label\n",
        "    true_label = int(y_test[idx])\n",
        "    temp, mask = exp.get_image_and_mask(\n",
        "        label=true_label,\n",
        "        positive_only=False,\n",
        "        hide_rest=False,\n",
        "        num_features=NUM_FEATURES,\n",
        "        min_weight=0.0,\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(mark_boundaries(temp, mask), cmap=\"gray\")\n",
        "    # >>> correção aqui: f-string sem quebra/aspas faltando <<<\n",
        "    title = f\"idx {idx} | true: {'smile' if true_label==1 else 'not_smile'} | pred: {'smile' if pred==1 else 'not_smile'} | p(smile)={p_smile:.3f}\"\n",
        "    plt.title(f\"LIME — {title}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.savefig(out_path, dpi=180, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "# Run\n",
        "for i, idx in enumerate(picked, start=1):\n",
        "    out_file = os.path.join(FIG_DIR, f\"exp_sample{i}.png\")\n",
        "    explain_and_save(idx, out_file)\n",
        "    print(f\"Saved: {out_file}\")\n"
      ],
      "metadata": {
        "id": "TiViVkv8H8FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import os, glob\n",
        "import numpy as np\n",
        "\n",
        "FIG_DIR = \"figures\"\n",
        "\n",
        "# Collect all generated explanation PNGs\n",
        "files = sorted(glob.glob(os.path.join(FIG_DIR, \"exp_sample*.png\")))\n",
        "print(f\"Found {len(files)} files\")\n",
        "\n",
        "def make_grid(image_paths, out_path, title, cols=4):\n",
        "    rows = int(np.ceil(len(image_paths) / cols))\n",
        "    plt.figure(figsize=(cols*3, rows*3))\n",
        "    for i, f in enumerate(image_paths, 1):\n",
        "        img = imread(f)\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(os.path.basename(f), fontsize=8)\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"Saved grid: {out_path}\")\n",
        "\n",
        "# Separate by class using y_test and picked\n",
        "smile_files = []\n",
        "not_smile_files = []\n",
        "\n",
        "for i, idx in enumerate(picked, start=1):\n",
        "    f = os.path.join(FIG_DIR, f\"exp_sample{i}.png\")\n",
        "    if not os.path.exists(f):\n",
        "        continue\n",
        "    if y_test[idx] == 1:\n",
        "        smile_files.append(f)\n",
        "    else:\n",
        "        not_smile_files.append(f)\n",
        "\n",
        "# Generate grids\n",
        "make_grid(smile_files, os.path.join(FIG_DIR, \"exp_grid_smile.png\"), \"LIME Explanations — Smile\")\n",
        "make_grid(not_smile_files, os.path.join(FIG_DIR, \"exp_grid_not_smile.png\"), \"LIME Explanations — Not Smile\")\n"
      ],
      "metadata": {
        "id": "1EQaDWDOI71C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get model predictions on the full test set\n",
        "flat_X = X_test.reshape(len(X_test), -1) if X_test.ndim > 2 else X_test\n",
        "probs = model.predict(flat_X, verbose=0).reshape(-1)\n",
        "preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "# Identify correct and incorrect indices\n",
        "correct_idx = np.where(preds == y_test)[0]\n",
        "incorrect_idx = np.where(preds != y_test)[0]\n",
        "\n",
        "print(f\"Correct predictions: {len(correct_idx)}\")\n",
        "print(f\"Incorrect predictions: {len(incorrect_idx)}\")\n",
        "\n",
        "# Example: pick a few incorrect cases for inspection\n",
        "sample_errors = incorrect_idx[:5]\n",
        "\n",
        "print(\"Sample misclassified indices:\", sample_errors)\n"
      ],
      "metadata": {
        "id": "1S-C15ADXQqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j, idx in enumerate(sample_errors, start=1):\n",
        "    out_path = os.path.join(FIG_DIR, f\"exp_error{j}.png\")\n",
        "    explain_and_save(idx, out_path)\n",
        "    print(f\"Saved error explanation: {out_path}\")\n"
      ],
      "metadata": {
        "id": "7pTmAdSRXvEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finished\n",
        "\n",
        "**Artifacts:**\n",
        "\n",
        "Final model: `models/mlp_smile_final.keras`\n",
        "\n",
        "Best checkpoint: `models/mlp_smile_best.keras`\n",
        "\n",
        "Training history: `models/mlp_smile_history.json`\n",
        "\n",
        "Evaluation report: results/classification_report.txt\n",
        "\n",
        "**Figures:**\n",
        "\n",
        "`figures/mlp_accuracy.png`\n",
        "\n",
        "`figures/mlp_loss.png`\n",
        "\n",
        "`figures/mlp_confusion_matrix.png`\n",
        "\n",
        "`figures/lime_*.png (individual explanations)`\n",
        "\n",
        "`figures/exp_grid_*.png (grids by class)`"
      ],
      "metadata": {
        "id": "BGe8sYfgONE_"
      }
    }
  ]
}